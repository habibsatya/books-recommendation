# -*- coding: utf-8 -*-
"""books-recommendation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fzl5CRvL4FZgn-lZvZWPoQDziBDLlG5o

# Proyek Machine Learning Terapan Bagian Akhir - Lalu Habib Satya Wiguna
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
from sklearn import neighbors
from sklearn.cluster import KMeans
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler

warnings.filterwarnings('ignore')
# %matplotlib inline

"""## Domain Knowledge
Langkah pertama yang kita lakukan adalah melihat isi dataset yang akan digunakan serta memahami setiap atribut yang ada pada dataset tersebut. Dataset yang digunakan yaitu [Goodreads-books](https://www.kaggle.com/datasets/jealousleopard/goodreadsbooks) yang didapaatkan dari situs [kaggle](https://www.kaggle.com)
"""

books = pd.read_csv('books.csv', error_bad_lines=False, warn_bad_lines=False)
books

"""Dari output di atas kita mempunyai 11123 data dengan 12 kolom pada Goodreads-books dataset. Berdasarkan informasi dari Kaggle, variabel-variabel pada Goodreads-books dataset adalah sebagai berikut:  
- bookID : kode unik dari setiap buku.
- title : nama atau judul dari buku.
- authors : nama dari penulis buku.
- average_rating : rata-rata penilaian dari setiap buku.
- isbn : kode unik buku yang merujuk pada ISBN (International Standard Book Number).
- isbn13 : 13-digit ISBN untuk mengidentifikasi buku.
- language_code : kode bahasa dari buku, misalnya 'eng' untuk English.
- num_pages : jumlah halaman dari buku.
- ratings_count : total penilaian yang didapatkan dari suatu buku.
- text_reviews_count : total teks review yang diperoleh oleh suatu buku.
- publication_date : tanggal buku dirilis ke publik.
- publisher : nama penerbit yang menerbitkan buku.
"""

books.info()

"""Dari output di atas dapat dilihat bahwa:

- Terdapat 6 kolom dengan tipe object, yaitu: title, authors, isbn, language_code, publication_date, publisher.
- Terdapat 5 kolom numerik dengan tipe int64, yaitu: bookID, isbn13, num_pages, ratings_count, text_review_count.
- Terdapat 1 kolom numerik dengan tipe float64, yaitu: average_rating.
"""

list(books)

"""Dapat dilihat pada output di atas bahwa ada variabel yang penulisannya memiliki spasi di awal yaitu num_pages. Oleh karena itu kita perlu memperbaikinya agar lebih mudah untuk diakses nanti."""

# menghapus spasi pada variabel num_pages agar memudahkan pengaksesan variabel nanti

books.columns = books.columns.str.strip()
list(books)

books.describe()

"""Fungsi describe() memberikan informasi statistik pada masing-masing kolom, antara lain:

- Count adalah jumlah sampel pada data.
- Mean adalah nilai rata-rata.
- Std adalah standar deviasi.
- Min yaitu nilai minimum setiap kolom.
- 25% adalah kuartil pertama. Kuartil adalah nilai yang menandai batas interval - dalam empat bagian sebaran yang sama.
- 50% adalah kuartil kedua, atau biasa juga disebut median (nilai tengah).
- 75% adalah kuartil ketiga.
- Max adalah nilai maksimum.

## Data Cleaning
Pada tahap ini, kita akan melakukan pembersihan pada data yaitu dengan menghapus data duplikat (jika ada), melihat data yang bernilai kosong, serta memperbaiki isi pada beberapa kolom agar lebih mudah membaca datanya.

### Checking Null Value
Pada tahap ini kita perlu memastikan apakah ada data dengan nilai kosong pada dataset kita karena akan memiliki pengaruh pada proses pembuatan model rekomendasi nanti jika data kita memiliki informasi yang kurang.
"""

# melihat apakah ada data yang memiliki nilai kosong

books.isnull().sum()

"""Dari output di atas kita dapat melihat bahwa seluruh kolom pada dataset kita tidak memiliki nilai kosong atau null value.

### Checking Duplicated Data
Pada tahap ini kita akan memeriksa apakah ada data duplikat pada dataset yang kita gunakan. Jika ada maka kita perlu untuk menghapusnya agar tidak boros informasi serta mengurangi kemungkinan overfitting.
"""

books.duplicated().sum()

"""Tidak ada data duplikat di dalam dataset.

### Fixing the Data
Pada tahap ini kita perlu mengubah isi pada kolom language_code agar memudahkan kita untuk mengetahui bahasa yang digunakan pada suatu buku. Kemudian kita akan menambahkan satu kolom baru di dataset kita yaitu publication_year yang berisi tentang informasi terkait tahun terbit dari suatu buku.
"""

books.language_code.unique()

"""Dari output di atas dapat dilihat bahwa akan sulit untuk mengetahui bahasa dari suatu buku apabila bentuk datanya seperti di atas. Oleh karena itu kita akan mengubahnya agar menjadi lebih mudah dibaca."""

books.language_code.replace(
    to_replace=[
        "eng",
        "en-US",
        "fre",
        "spa",
        "en-GB",
        "mul",
        "grc",
        "enm",
        "en-CA",
        "ger",
        "jpn",
        "ara",
        "nl",
        "zho",
        "lat",
        "por",
        "srp",
        "ita",
        "rus",
        "msa",
        "glg",
        "wel",
        "swe",
        "nor",
        "tur",
        "gla",
        "ale",
    ],
    value=[
        "English",
        "US-English",
        "French",
        "Spanish",
        "British-English",
        "Multiple language",
        "Greek",
        "Middle English",
        "Canada-English",
        "German",
        "Japanese",
        "Arabic",
        "Dutch",
        "Chinese",
        "Latvian",
        "Portuguese",
        "Serbian",
        "Initial Teaching language",
        "Russian",
        "Modern Standard Arabic",
        "Galician",
        "Welsh",
        "Swedish",
        "Murik",
        "Turkish",
        "Gaelic",
        "Afro-Asiatic",
    ],
    inplace=True,
)
books.language_code.unique()

"""Data pada kolom language_code sekarang menjadi lebih mudah dibaca. Selanjutnya kita akan mengubah nama kolom language_code menjadi language saja karena sudah bukan berbentuk kode lagi."""

books = books.rename(columns={'language_code':'language'})

"""Selanjutnya kita akan menambahkan kolom dengan nama publication_year yang berisi tentang informasi terkait tahun terbit dari suatu buku."""

books['publication_year'] = books['publication_date'].apply(lambda x: (int)(str(x[-4:])))

books.head()

"""Dapat dilihat dari output di atas, dataset sekarang menjadi lebih enak untuk dilihat dan lebih mudah dibaca.

## Exploratory Data Analysis
Pada tahap ini, kita akan melakukan ekplorasi terhadap variabel-variabel yang ada pada dataset yang kita gunakan. Pemahaman terhadap variabel ini penting karena akan membantu kita dalam menentukan pendekatan atau algoritma yang cocok untuk data kita.
"""

list(books)

num_of_author = books['authors'].duplicated().sum()
author = books.authors.value_counts()[0:10]
print('Total of Authors: ', num_of_author)
print(author)

plt.figure(figsize=(15, 10))
sns.barplot(x=author, y=author.index)
plt.xticks(rotation=90)
plt.ylabel('Authors')
plt.xlabel('Number of Books Has Written')
plt.show()

"""Berdasarkan output di atas, dari total 4484 penulis dapat kita lihat Top-10 penulis dengan buku terbanyak yang telah ditulis. Author dengan buku terbanyak yang ditulis adalah Stephen King sebanyak 40 buku. """

num_of_pub = books['publisher'].duplicated().sum()
publisher = books.publisher.value_counts()[0:10]
print('Total of Publishers: ', num_of_pub)
print(publisher)

plt.figure(figsize=(15,10))
sns.barplot(x=publisher,y=publisher.index)
plt.xticks(rotation=90)
plt.ylabel('Publishers')
plt.xlabel('Number of Books Has Publisher')
plt.show()

"""Dari output di atas kita dapat melihat Top-10 penerbit dengan buku yang telah diterbitkan dari total 8833 penerbit. Vintage merupakan penerbit yang menerbitkan buku terbanyak dengan total 318 buku yang telah diterbitkan di bawah nama Vintage."""

num_of_lang = books['language'].nunique()
languages = books.language.value_counts()[0:10]
print('Total of Languages: ', num_of_lang)
print(languages)

plt.figure(figsize=(15, 10))
sns.barplot(x=languages.index, y=languages)
plt.ylabel('Count')
plt.xlabel('Languages')
plt.show()

"""Dari total 27 bahasa, Inggris merupakan bahasa yang paling banyak digunakan pada buku yang ada di dataset dengan total 8908 buku yang ditulis dalam bahasa Inggris."""

year = books['publication_year'].value_counts()[0:10]
print(year)

plt.figure(figsize=(15,10))
sns.barplot(x=year.index, y=year)
plt.ylabel('Count')
plt.xlabel('Year')
plt.show()

"""Berdasarkan grafik di atas, tahun 2006 merupakan tahun di mana buku paling banyak diterbitkan dengan total 1700 buku yang diterbitkan pada tahun tersebut."""

average_rating = round(books['average_rating'].mean(), 2)
print('Average Rating of All Books : ', average_rating)

graph = sns.displot(books, x='average_rating', kind='kde', fill=True);
graph.fig.set_figwidth(10)

"""Berdasarkan grafik di atas, rata-rata penilaian atau rating yang diberikan untuk semua buku adalah 3.93."""

top_10_rating = books[books['ratings_count']>1000000].sort_values(by='ratings_count', ascending=False)[0:10]

plt.figure(figsize=(15,10))
sns.barplot(x=top_10_rating.ratings_count, y=top_10_rating['title'])
plt.ylabel('Title')
plt.xlabel('Ratings Count')
plt.ticklabel_format(style='plain', axis='x')
plt.show()

"""Berdasarkan grafik di atas, buku dengan judul Twilight menempati posisi teratas untuk buku dengan rating terbanyak yang diberikan."""

top_10_books = top_10_rating.sort_values(by='average_rating', ascending=False)[0:10]

plt.figure(figsize=(15,10))
sns.barplot(x=top_10_books.average_rating, y=top_10_books['title'])
plt.ylabel('Title')
plt.xlabel('Rating')
plt.ticklabel_format(style='plain', axis='x')
plt.show()

"""Berdasarkan grafik di atas, buku dengan judul Harry Potter and the Half-Blood Prince menempati posisi teratas untuk buku dengan rating tertinggi."""

plt.figure(figsize=(15, 10))
correlation_matrix = books.corr().round(2)
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")

"""Dari hasil metrik korelasi di atas, kita dapat melihat bahwa variabel text_review_count dengan ratings_count memiliki korelasi yang sangat baik. Perlu diketahui bahwa semakin mendekati angka 1 maka korelasi akan semakin bagus. Oleh karena itu kita perlu melihat hubungan antara average_rating dengan variabel lainnya karena di sini rating memiliki pengaruh yang besar untuk merekomendasikan suatu buku kepada pengguna."""

plt.figure(figsize=(10, 8))
sns.scatterplot(data=books, x='average_rating', y='ratings_count')
plt.show()

plt.figure(figsize=(10, 8))
sns.scatterplot(data=books, x='average_rating', y='text_reviews_count')
plt.show()

plt.figure(figsize=(10, 8))
sns.scatterplot(data=books, x='average_rating', y='num_pages')
plt.show()

plt.figure(figsize=(10, 8))
sns.scatterplot(data=books, x='average_rating', y='language')
plt.show()

"""Dari hasil scatterplot di atas, dapat diambil kesimpulan sebagai berikut:
- Tidak ada korelasi khusus antara variabel average_rating dengan variabel ratings_count, text_reviews_count, dan num_pages.
- Variabel average_rating dengan variabel language memiliki distribusi penyebaran yang baik sehingga kita akan menggunakan kedua variabel tersebut untuk merekomendasikan buku nanti.

## Data Preparation
Pada bagian ini, kita akan melakukan persiapan padaa dataset kita agar lebih mudah pada tahap pemodelan nanti.
"""

books.loc[(books['average_rating'] >= 0) & (books['average_rating'] <= 1), 'rating_between'] = "between 0 and 1"
books.loc[(books['average_rating'] > 1) & (books['average_rating'] <= 2), 'rating_between'] = "between 1 and 2"
books.loc[(books['average_rating'] > 2) & (books['average_rating'] <= 3), 'rating_between'] = "between 2 and 3"
books.loc[(books['average_rating'] > 3) & (books['average_rating'] <= 4), 'rating_between'] = "between 3 and 4"
books.loc[(books['average_rating'] > 4) & (books['average_rating'] <= 5), 'rating_between'] = "between 4 and 5"

"""Selanjutnya kita menambahkan kolom dengan nama rating_between yang berisikan rating antara 0 sampai 1, 1 sampai 2, 2 sampai 3,3 sampai 4, dan 4 sampai 5. Hal tersebut dilakukan agar sistem kita bekerja dengan maksimal untuk menghasilkan rekomendasi yang baik."""

books.head()

books_rating = pd.get_dummies(books['rating_between'])
books_language = pd.get_dummies(books['language'])

"""Kita memisahkan variabel rating_between dan language dengan membuat dataframe baru untuk masing-masing variabel."""

books_rating.head()

books_language.head()

features = pd.concat([books_rating, books_language, books['average_rating'], books['ratings_count']], axis=1)
features.head()

"""Kemudian kita akan membuat dataframe baru dengan menggabungkan beberapa data seperti books_rating, books_language, average_rating, dan ratings_count sehingga pada tahap pemodelan dataset kita sudah siap digunakan dan dimasukkan ke sistem rekomendasi.

## Model Development Using Collaborative Filtering
Untuk proyek kali ini, akan digunakan collaboreative filtering pada sistem rekomendasinya. Collaborative filtering akan memberikan rekomendasi buku berdasarkan rating yang telah diberikan sebelumnya untuk suatu buku. Dari data rating buku, kita akan mengidentifikasi buku-buku yang mirip dengan menggunakan algoritma K-Nearest Neighbor (KNN) untuk direkomendasikan ke pengguna. KNN adalah algoritma yang relatif sederhana dibandingkan dengan algoritma lain. Algoritma KNN menggunakan 'kesamaan fitur' untuk memprediksi nilai dari setiap data yang baru. Dengan kata lain, setiap data baru diberi nilai berdasarkan seberapa mirip titik tersebut dalam set pelatihan.KNN bekerja dengan membandingkan jarak satu sampel ke sampel pelatihan lain dengan memilih sejumlah k tetangga terdekat (dengan k adalah sebuah angka positif). Nah, itulah mengapa algoritma ini dinamakan K-nearest neighbor (sejumlah k tetangga terdekat). KNN bisa digunakan untuk kasus klasifikasi dan regresi. Pada kali ini, kita akan menggunakannya untuk membuat sebuah sistem rekomendasi.
"""

min_max_scaler = MinMaxScaler()
features = min_max_scaler.fit_transform(features)

"""Pertama-tama kita perlu melakukan penskalaan pada dataset kita untuk mengurangi bias karena beberapa buku memiliki banyak fitur. Secara garis besar kita mencari nilai tengah dari fitur-fitur tersebut untuk kemudian disamaratakan."""

features

model = neighbors.NearestNeighbors(n_neighbors=11)
model.fit(features)
books_dist, books_idlist = model.kneighbors(features)

"""Selanjutnya kita akan memasukkan data ke dalam model KNN dengan parameter n_neighbors=11 yang berarti kita akan mengambil 10 buku teratas yang memiliki kemiripan untuk direkomendasikan kepada pengguna. Mengapa 11? karena buku pertama akan mengarah ke buku itu sendiri, oleh karena itu untuk mengambil 10 buku teratas kita akan melewati 1 buku pertama dan menyimpan 10 buku setelahnya dengan menggunakan nilai 11 pada parameter n_neighbors."""

def BookRecommender(book_name):
    book_list_name = []
    book_features = []
    book_id = books[books['title'] == book_name].index
    book_id = book_id[0]
    for newid in books_idlist[book_id]:
        book_list_name.append(books.loc[newid].title)
        book_features.append(books_dist[newid])
    return book_list_name, book_features

"""Selanjutnya kita membuat sebuah function yang berfungsi untuk melakukan filtering terhadap buku yang akan direkomendasikan dengan parameter function yaitu judul buku. Dari judul buku tersebut kemudian akan dicari buku lain yang memiliki kemiripan dengan menggunakan model KNN yang telah dibuat sebelumnya. Function ini akan me-return list dengan isi judul-judul buku yang memiliki fitur mirip dengan judul buku yang dimasukkan."""

books_recommendation, books_features = BookRecommender('The Book Thief')
books_recommendation[1:]

books_features

"""Berdasarkan output di atas, sistem kita telah berhasil merekomendasikan buku yang memiliki kemiripan dengan judul buku yang kita masukkan sebagai parameter pada function BookRecommender. Lalu kita juga berhasil mendapatkan vektor dari buku-buku yang mirip untuk digunakan nanti pada tahap evaluasi.

## Model Evaluation

Pada tahap evaluasi ini kita akan melakukan pengujian menggunakan cosine similarity. Cosine similarity membantu kita untuk melihat kemiripan antara buku yang yang satu dengan yang lain menggunakan features yang sebelumnya kita dapatkan. Dengan menggunakan cosine similarity kita akan mengetahui sudut cosine yang dibentuk dengan cara menghitung angle yang diberikan dari dua buah vector items. Nantinya hasil perhitungan tersebut akan memperlihatkan nilai antara 0-1. Semakin dekat nilai dengan angka 0 maka semakin sedikit kemiripan antara dua buah items tersebut, sebaliknya semakin dekat dengan 1 berarti items tersebut memiliki kemiripan features. Output akan bernilai 1 apabila sebuah item dibandingkan dengan item itu sendiri.
"""

index_values = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10']
column_values = ['Books_Title']

books_rec = pd.DataFrame(data=books_recommendation, index=index_values, columns=column_values)
books_rec

"""Pertama-tama kita membuat sebuah dataframe yang berisikan judul buku dan feature yang dimilikinya untuk mempermudah melihat data apa saja yang ada."""

books_rec['Features'] = books_features
books_rec

from numpy.linalg import norm

cosine_sim = []
for features in range(len(books_rec['Features'])):
    cosine = np.dot(books_rec['Features'][0], books_rec['Features'][features])/(norm(books_rec['Features'][0])*norm(books_rec['Features'][features]))
    cosine_sim.append(cosine)
    print("Cosine Similarity:", cosine)

"""Selanjutnya kita menghitung cosine similarity antara buku yang diinputkan dengan buku-buku yang direkomendasikan. Kemudian pada output di atas dapat dilihat bahwa keseluruhan buku-buku yang direkomendasikan memiliki nilai cosine similarity yang hampir mendekati angka 1 yang berarti bahwa buku-buku tersebut sudah relevan dengan buku yang diinputkan."""

books_rec['cosine_sim'] = cosine_sim
books_rec

"""Kemudian untuk mempermudah dalam menganalisis data, kita menggabungkan hasil perhitungan cosine similarity yang didapat tadi ke dalam dataframe dan didapatkan output seperti di atas. Ternyata sistem rekomendasi yang dibuat sudah bisa melakukan rekomendasi berdasarkan kemiripan rating dan bahasa yang dimiliki oleh suatu buku."""